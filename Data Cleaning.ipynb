{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reviews DataFrame:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 21712798 entries, 0 to 21944801\n",
      "Data columns (total 8 columns):\n",
      " #   Column   Dtype  \n",
      "---  ------   -----  \n",
      " 0   user_id  object \n",
      " 1   name     object \n",
      " 2   time     int64  \n",
      " 3   rating   float64\n",
      " 4   text     object \n",
      " 5   pics     object \n",
      " 6   resp     object \n",
      " 7   gmap_id  object \n",
      "dtypes: float64(1), int64(1), object(6)\n",
      "memory usage: 1.5+ GB\n",
      "None\n",
      "\n",
      "Metadata DataFrame:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 189836 entries, 0 to 190815\n",
      "Data columns (total 15 columns):\n",
      " #   Column            Non-Null Count   Dtype  \n",
      "---  ------            --------------   -----  \n",
      " 0   name              189836 non-null  object \n",
      " 1   address           189836 non-null  object \n",
      " 2   gmap_id           189836 non-null  object \n",
      " 3   description       189836 non-null  object \n",
      " 4   latitude          189836 non-null  float64\n",
      " 5   longitude         189836 non-null  float64\n",
      " 6   category          189836 non-null  object \n",
      " 7   avg_rating        189836 non-null  float64\n",
      " 8   num_of_reviews    189836 non-null  int64  \n",
      " 9   price             189836 non-null  object \n",
      " 10  hours             189836 non-null  object \n",
      " 11  MISC              189836 non-null  object \n",
      " 12  state             189836 non-null  object \n",
      " 13  relative_results  189836 non-null  object \n",
      " 14  url               189836 non-null  object \n",
      "dtypes: float64(3), int64(1), object(11)\n",
      "memory usage: 23.2+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "import gzip\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "def parse_json_gz(file_path):\n",
    "        with open(file_path, 'r') as f:\n",
    "            for line in f:\n",
    "                yield json.loads(line)\n",
    "\n",
    "reviews = list(parse_json_gz(r'C:\\MS DS\\RG_Winter25\\Capstone 1 DSCI 591\\data\\review-Pennsylvania.json\\review-Pennsylvania.json'))\n",
    "metadata = list(parse_json_gz(r'C:\\MS DS\\RG_Winter25\\Capstone 1 DSCI 591\\data\\meta-Pennsylvania.json\\meta-Pennsylvania.json'))\n",
    "\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "reviews = pd.DataFrame(reviews)\n",
    "metadata = pd.DataFrame(metadata)\n",
    "# Identify all columns with dtype 'object'\n",
    "object_cols = reviews.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Convert those columns to string\n",
    "reviews[object_cols] = reviews[object_cols].astype(str)\n",
    "reviews.drop_duplicates(inplace=True)\n",
    "# Identify all columns with dtype 'object'\n",
    "object_cols = metadata.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Convert those columns to string\n",
    "metadata[object_cols] = metadata[object_cols].astype(str)\n",
    "metadata.drop_duplicates(inplace=True)\n",
    "\n",
    "print(\"Reviews DataFrame:\")\n",
    "print(reviews.info())\n",
    "print(\"\\nMetadata DataFrame:\")\n",
    "print(metadata.info())\n",
    "def merge_datasets(reviews, metadata, merge_on='gmap_id'):\n",
    "    return pd.merge(reviews, metadata, on=merge_on, how='left')\n",
    "\n",
    "\n",
    "object_cols = metadata.select_dtypes(include=['object']).columns\n",
    "\n",
    "\n",
    "\n",
    "merged_data_df = merge_datasets(reviews, metadata)\n",
    "def handle_missing_values(df):\n",
    "    drop_subset = ['user_id', 'rating']\n",
    "    text_columns = ['text', 'description', 'resp']\n",
    "    categorical_columns = ['name_x', 'name_y', 'category', 'price', 'address', 'hours', 'MISC', 'url']\n",
    "    \n",
    "    # Dropping rows with missing critical fields\n",
    "    df = df.dropna(subset=drop_subset)\n",
    "\n",
    "    # Filling text columns with empty strings\n",
    "    for col in text_columns:\n",
    "        if col in df.columns:\n",
    "            df[col] = df[col].fillna(\"\")\n",
    "\n",
    "\n",
    "    # Filling categorical columns with \"unknown\"\n",
    "    for col in categorical_columns:\n",
    "        if col in df.columns:\n",
    "            df[col] = df[col].fillna(\"unknown\")\n",
    "    \n",
    "    return df\n",
    "df = handle_missing_values(merged_data_df)\n",
    "if 'time' in df.columns:\n",
    "    try:\n",
    "        df['time'] = pd.to_datetime(df['time'], unit='ms')\n",
    "    except Exception:\n",
    "        df['time'] = pd.to_datetime(df['time'], errors='coerce')\n",
    "numeric_fields = ['rating','user_id', 'avg_rating', 'num_of_reviews', 'latitude', 'longitude']\n",
    "for field in numeric_fields:\n",
    "    if field in df.columns:\n",
    "        df[field] = pd.to_numeric(df[field], errors='coerce')\n",
    "\n",
    "df.rename(columns={'name_x': 'customer_name', 'name_y': 'business_name'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "object_cols = df.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Convert those columns to string\n",
    "df[object_cols] = df[object_cols].astype(str)\n",
    "\n",
    "columns_to_fix = df[object_cols] # Replace with actual column names\n",
    "for col in columns_to_fix:\n",
    "    df[col] = df[col].astype(str).str.replace(\"\\x00\", \"\", regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>customer_name</th>\n",
       "      <th>time</th>\n",
       "      <th>rating</th>\n",
       "      <th>text</th>\n",
       "      <th>resp</th>\n",
       "      <th>gmap_id</th>\n",
       "      <th>business_name</th>\n",
       "      <th>address</th>\n",
       "      <th>description</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>avg_rating</th>\n",
       "      <th>num_of_reviews</th>\n",
       "      <th>price</th>\n",
       "      <th>state</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.136701e+20</td>\n",
       "      <td>Michelle OBrien</td>\n",
       "      <td>1990-12-31</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Flatbreads are delicious for appetizers to sha...</td>\n",
       "      <td>None</td>\n",
       "      <td>0x89c6944bbcf4f9fb:0x77c6109d1ce368f4</td>\n",
       "      <td>Seasons 52</td>\n",
       "      <td>Seasons 52, 160 N Gulph Rd Suite 101, King of ...</td>\n",
       "      <td>Rotating menu of seasonal American dishes alon...</td>\n",
       "      <td>40.085768</td>\n",
       "      <td>-75.394432</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1618</td>\n",
       "      <td>$$</td>\n",
       "      <td>PA</td>\n",
       "      <td>https://www.google.com/maps/place//data=!4m2!3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.004704e+20</td>\n",
       "      <td>Howard Dinin</td>\n",
       "      <td>1990-12-31</td>\n",
       "      <td>4.0</td>\n",
       "      <td>well-run and clearly a popular \"happening\" spo...</td>\n",
       "      <td>None</td>\n",
       "      <td>0x89c6c630798d07a5:0x7da1292822f531db</td>\n",
       "      <td>Alma de Cuba</td>\n",
       "      <td>Alma de Cuba, 1623 Walnut St, Philadelphia, PA...</td>\n",
       "      <td>Fusion fare with Cuban influences; happy hour ...</td>\n",
       "      <td>39.950078</td>\n",
       "      <td>-75.168517</td>\n",
       "      <td>4.4</td>\n",
       "      <td>998</td>\n",
       "      <td>$$$</td>\n",
       "      <td>PA</td>\n",
       "      <td>https://www.google.com/maps/place//data=!4m2!3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1.138597e+20</td>\n",
       "      <td>Joe Nicolas</td>\n",
       "      <td>1990-12-31</td>\n",
       "      <td>5.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0x89c6c625b14dea8b:0xb31072102487e2fe</td>\n",
       "      <td>VALANNI</td>\n",
       "      <td>VALANNI, 1229 Spruce St, Philadelphia, PA 1910...</td>\n",
       "      <td>Distinctive Mediterranean-Latin dishes served ...</td>\n",
       "      <td>39.946850</td>\n",
       "      <td>-75.162217</td>\n",
       "      <td>4.3</td>\n",
       "      <td>448</td>\n",
       "      <td>$$</td>\n",
       "      <td>PA</td>\n",
       "      <td>https://www.google.com/maps/place//data=!4m2!3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1.004403e+20</td>\n",
       "      <td>Chef Marsha Kiv</td>\n",
       "      <td>1990-12-31</td>\n",
       "      <td>3.0</td>\n",
       "      <td>I have been to many of Chef Garces' restaurant...</td>\n",
       "      <td>None</td>\n",
       "      <td>0x89c6c6f86d1010ad:0x2fb936cf6717b44d</td>\n",
       "      <td>Distrito</td>\n",
       "      <td>Distrito, 3945 Chestnut St, Philadelphia, PA 1...</td>\n",
       "      <td>Mexican bites &amp; potent margaritas flavor this ...</td>\n",
       "      <td>39.955999</td>\n",
       "      <td>-75.202017</td>\n",
       "      <td>4.0</td>\n",
       "      <td>838</td>\n",
       "      <td>$$</td>\n",
       "      <td>PA</td>\n",
       "      <td>https://www.google.com/maps/place//data=!4m2!3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1.178880e+20</td>\n",
       "      <td>Melody Tsai</td>\n",
       "      <td>1990-12-31</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Great Food!</td>\n",
       "      <td>None</td>\n",
       "      <td>0x89c6c60e85b145bf:0xb189cdb4c35a41f3</td>\n",
       "      <td>South Philadelphia Tap Room</td>\n",
       "      <td>South Philadelphia Tap Room, 1509 Mifflin St, ...</td>\n",
       "      <td>American beer bar featuring a lineup of drafts...</td>\n",
       "      <td>39.927216</td>\n",
       "      <td>-75.171477</td>\n",
       "      <td>4.6</td>\n",
       "      <td>746</td>\n",
       "      <td>$$</td>\n",
       "      <td>PA</td>\n",
       "      <td>https://www.google.com/maps/place//data=!4m2!3...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id       user_id    customer_name       time  rating  \\\n",
       "0   0  1.136701e+20  Michelle OBrien 1990-12-31     4.0   \n",
       "1   1  1.004704e+20     Howard Dinin 1990-12-31     4.0   \n",
       "2   2  1.138597e+20      Joe Nicolas 1990-12-31     5.0   \n",
       "3   3  1.004403e+20  Chef Marsha Kiv 1990-12-31     3.0   \n",
       "4   4  1.178880e+20      Melody Tsai 1990-12-31     5.0   \n",
       "\n",
       "                                                text  resp  \\\n",
       "0  Flatbreads are delicious for appetizers to sha...  None   \n",
       "1  well-run and clearly a popular \"happening\" spo...  None   \n",
       "2                                               None  None   \n",
       "3  I have been to many of Chef Garces' restaurant...  None   \n",
       "4                                        Great Food!  None   \n",
       "\n",
       "                                 gmap_id                business_name  \\\n",
       "0  0x89c6944bbcf4f9fb:0x77c6109d1ce368f4                   Seasons 52   \n",
       "1  0x89c6c630798d07a5:0x7da1292822f531db                 Alma de Cuba   \n",
       "2  0x89c6c625b14dea8b:0xb31072102487e2fe                      VALANNI   \n",
       "3  0x89c6c6f86d1010ad:0x2fb936cf6717b44d                     Distrito   \n",
       "4  0x89c6c60e85b145bf:0xb189cdb4c35a41f3  South Philadelphia Tap Room   \n",
       "\n",
       "                                             address  \\\n",
       "0  Seasons 52, 160 N Gulph Rd Suite 101, King of ...   \n",
       "1  Alma de Cuba, 1623 Walnut St, Philadelphia, PA...   \n",
       "2  VALANNI, 1229 Spruce St, Philadelphia, PA 1910...   \n",
       "3  Distrito, 3945 Chestnut St, Philadelphia, PA 1...   \n",
       "4  South Philadelphia Tap Room, 1509 Mifflin St, ...   \n",
       "\n",
       "                                         description   latitude  longitude  \\\n",
       "0  Rotating menu of seasonal American dishes alon...  40.085768 -75.394432   \n",
       "1  Fusion fare with Cuban influences; happy hour ...  39.950078 -75.168517   \n",
       "2  Distinctive Mediterranean-Latin dishes served ...  39.946850 -75.162217   \n",
       "3  Mexican bites & potent margaritas flavor this ...  39.955999 -75.202017   \n",
       "4  American beer bar featuring a lineup of drafts...  39.927216 -75.171477   \n",
       "\n",
       "   avg_rating  num_of_reviews price state  \\\n",
       "0         4.4            1618    $$    PA   \n",
       "1         4.4             998   $$$    PA   \n",
       "2         4.3             448    $$    PA   \n",
       "3         4.0             838    $$    PA   \n",
       "4         4.6             746    $$    PA   \n",
       "\n",
       "                                                 url  \n",
       "0  https://www.google.com/maps/place//data=!4m2!3...  \n",
       "1  https://www.google.com/maps/place//data=!4m2!3...  \n",
       "2  https://www.google.com/maps/place//data=!4m2!3...  \n",
       "3  https://www.google.com/maps/place//data=!4m2!3...  \n",
       "4  https://www.google.com/maps/place//data=!4m2!3...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop specified columns\n",
    "df_new = df.drop(columns=['category', 'hours', 'MISC', 'relative_results','pics'])\n",
    "\n",
    "# Sort by 'time' column\n",
    "df_new = df_new.sort_values(by='time', ascending=True)\n",
    "\n",
    "# Reset index and set as 'id'\n",
    "df_new = df_new.reset_index(drop=True).rename_axis('id').reset_index()\n",
    "\n",
    "# Display first few rows\n",
    "df_new.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>customer_name</th>\n",
       "      <th>time</th>\n",
       "      <th>rating</th>\n",
       "      <th>text</th>\n",
       "      <th>resp</th>\n",
       "      <th>gmap_id</th>\n",
       "      <th>business_name</th>\n",
       "      <th>address</th>\n",
       "      <th>description</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>avg_rating</th>\n",
       "      <th>num_of_reviews</th>\n",
       "      <th>price</th>\n",
       "      <th>state</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.136701e+20</td>\n",
       "      <td>Michelle OBrien</td>\n",
       "      <td>1990-12-31</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Flatbreads are delicious for appetizers to sha...</td>\n",
       "      <td>None</td>\n",
       "      <td>0x89c6944bbcf4f9fb:0x77c6109d1ce368f4</td>\n",
       "      <td>Seasons 52</td>\n",
       "      <td>Seasons 52, 160 N Gulph Rd Suite 101, King of ...</td>\n",
       "      <td>Rotating menu of seasonal American dishes alon...</td>\n",
       "      <td>40.085768</td>\n",
       "      <td>-75.394432</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1618</td>\n",
       "      <td>$$</td>\n",
       "      <td>PA</td>\n",
       "      <td>https://www.google.com/maps/place//data=!4m2!3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.004704e+20</td>\n",
       "      <td>Howard Dinin</td>\n",
       "      <td>1990-12-31</td>\n",
       "      <td>4.0</td>\n",
       "      <td>well-run and clearly a popular \"happening\" spo...</td>\n",
       "      <td>None</td>\n",
       "      <td>0x89c6c630798d07a5:0x7da1292822f531db</td>\n",
       "      <td>Alma de Cuba</td>\n",
       "      <td>Alma de Cuba, 1623 Walnut St, Philadelphia, PA...</td>\n",
       "      <td>Fusion fare with Cuban influences; happy hour ...</td>\n",
       "      <td>39.950078</td>\n",
       "      <td>-75.168517</td>\n",
       "      <td>4.4</td>\n",
       "      <td>998</td>\n",
       "      <td>$$$</td>\n",
       "      <td>PA</td>\n",
       "      <td>https://www.google.com/maps/place//data=!4m2!3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1.138597e+20</td>\n",
       "      <td>Joe Nicolas</td>\n",
       "      <td>1990-12-31</td>\n",
       "      <td>5.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0x89c6c625b14dea8b:0xb31072102487e2fe</td>\n",
       "      <td>VALANNI</td>\n",
       "      <td>VALANNI, 1229 Spruce St, Philadelphia, PA 1910...</td>\n",
       "      <td>Distinctive Mediterranean-Latin dishes served ...</td>\n",
       "      <td>39.946850</td>\n",
       "      <td>-75.162217</td>\n",
       "      <td>4.3</td>\n",
       "      <td>448</td>\n",
       "      <td>$$</td>\n",
       "      <td>PA</td>\n",
       "      <td>https://www.google.com/maps/place//data=!4m2!3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1.004403e+20</td>\n",
       "      <td>Chef Marsha Kiv</td>\n",
       "      <td>1990-12-31</td>\n",
       "      <td>3.0</td>\n",
       "      <td>I have been to many of Chef Garces' restaurant...</td>\n",
       "      <td>None</td>\n",
       "      <td>0x89c6c6f86d1010ad:0x2fb936cf6717b44d</td>\n",
       "      <td>Distrito</td>\n",
       "      <td>Distrito, 3945 Chestnut St, Philadelphia, PA 1...</td>\n",
       "      <td>Mexican bites &amp; potent margaritas flavor this ...</td>\n",
       "      <td>39.955999</td>\n",
       "      <td>-75.202017</td>\n",
       "      <td>4.0</td>\n",
       "      <td>838</td>\n",
       "      <td>$$</td>\n",
       "      <td>PA</td>\n",
       "      <td>https://www.google.com/maps/place//data=!4m2!3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1.178880e+20</td>\n",
       "      <td>Melody Tsai</td>\n",
       "      <td>1990-12-31</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Great Food!</td>\n",
       "      <td>None</td>\n",
       "      <td>0x89c6c60e85b145bf:0xb189cdb4c35a41f3</td>\n",
       "      <td>South Philadelphia Tap Room</td>\n",
       "      <td>South Philadelphia Tap Room, 1509 Mifflin St, ...</td>\n",
       "      <td>American beer bar featuring a lineup of drafts...</td>\n",
       "      <td>39.927216</td>\n",
       "      <td>-75.171477</td>\n",
       "      <td>4.6</td>\n",
       "      <td>746</td>\n",
       "      <td>$$</td>\n",
       "      <td>PA</td>\n",
       "      <td>https://www.google.com/maps/place//data=!4m2!3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>95</td>\n",
       "      <td>1.183500e+20</td>\n",
       "      <td>Dan F</td>\n",
       "      <td>2005-08-31</td>\n",
       "      <td>5.0</td>\n",
       "      <td>this could be the best byo in the burbs.  ever...</td>\n",
       "      <td>None</td>\n",
       "      <td>0x89c6c07607056697:0x2b8e2876e3a9517e</td>\n",
       "      <td>Sola</td>\n",
       "      <td>Sola, 614 Lancaster Ave, Bryn Mawr, PA 19010</td>\n",
       "      <td>New American seasonal cuisine served in a cozy...</td>\n",
       "      <td>40.018088</td>\n",
       "      <td>-75.312039</td>\n",
       "      <td>4.3</td>\n",
       "      <td>28</td>\n",
       "      <td>$$$</td>\n",
       "      <td>PA</td>\n",
       "      <td>https://www.google.com/maps/place//data=!4m2!3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>96</td>\n",
       "      <td>1.183500e+20</td>\n",
       "      <td>Dan F</td>\n",
       "      <td>2005-08-31</td>\n",
       "      <td>4.0</td>\n",
       "      <td>this neighborhood tap room really cooks.  ever...</td>\n",
       "      <td>None</td>\n",
       "      <td>0x89c6c898b3eb1341:0x12cfe87713184d11</td>\n",
       "      <td>New Wave Cafe</td>\n",
       "      <td>New Wave Cafe, 784 S 3rd St, Philadelphia, PA ...</td>\n",
       "      <td>Locals fill this casual sports bar to chat wit...</td>\n",
       "      <td>39.938080</td>\n",
       "      <td>-75.148527</td>\n",
       "      <td>4.4</td>\n",
       "      <td>435</td>\n",
       "      <td>$</td>\n",
       "      <td>PA</td>\n",
       "      <td>https://www.google.com/maps/place//data=!4m2!3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>97</td>\n",
       "      <td>1.051016e+20</td>\n",
       "      <td>Mac Frazier</td>\n",
       "      <td>2005-10-22</td>\n",
       "      <td>2.0</td>\n",
       "      <td>great traditional german food! the setting is ...</td>\n",
       "      <td>None</td>\n",
       "      <td>0x89c6afbf8417a279:0x3dd203c5ec7db1e3</td>\n",
       "      <td>Otto's Brauhaus</td>\n",
       "      <td>Otto's Brauhaus, 233 Easton Rd, Horsham, PA 19044</td>\n",
       "      <td>Prime rib, steaks, seafood &amp; German specialtie...</td>\n",
       "      <td>40.175800</td>\n",
       "      <td>-75.128520</td>\n",
       "      <td>4.0</td>\n",
       "      <td>678</td>\n",
       "      <td>$$</td>\n",
       "      <td>PA</td>\n",
       "      <td>https://www.google.com/maps/place//data=!4m2!3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>98</td>\n",
       "      <td>1.051016e+20</td>\n",
       "      <td>Mac Frazier</td>\n",
       "      <td>2005-10-22</td>\n",
       "      <td>2.0</td>\n",
       "      <td>cute, themed diner, with good shakes and burge...</td>\n",
       "      <td>None</td>\n",
       "      <td>0x89c6c2f455344797:0x12987ea5eabacd5a</td>\n",
       "      <td>Nifty Fifty's</td>\n",
       "      <td>Nifty Fifty's, 1900 MacDade Boulevard, Folsom,...</td>\n",
       "      <td>Nostalgic, '50s-style American diner with burg...</td>\n",
       "      <td>39.895706</td>\n",
       "      <td>-75.314895</td>\n",
       "      <td>4.4</td>\n",
       "      <td>3156</td>\n",
       "      <td>$</td>\n",
       "      <td>PA</td>\n",
       "      <td>https://www.google.com/maps/place//data=!4m2!3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>99</td>\n",
       "      <td>1.051016e+20</td>\n",
       "      <td>Mac Frazier</td>\n",
       "      <td>2005-10-22</td>\n",
       "      <td>2.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0x89c6b0ea14e77aeb:0xb00d8934ef9a7781</td>\n",
       "      <td>La Pergola</td>\n",
       "      <td>La Pergola, 726 West Ave, Jenkintown, PA 19046</td>\n",
       "      <td>Hummus &amp; Middle Eastern fare shares menu space...</td>\n",
       "      <td>40.095844</td>\n",
       "      <td>-75.126244</td>\n",
       "      <td>4.3</td>\n",
       "      <td>58</td>\n",
       "      <td>$$</td>\n",
       "      <td>PA</td>\n",
       "      <td>https://www.google.com/maps/place//data=!4m2!3...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    id       user_id    customer_name       time  rating  \\\n",
       "0    0  1.136701e+20  Michelle OBrien 1990-12-31     4.0   \n",
       "1    1  1.004704e+20     Howard Dinin 1990-12-31     4.0   \n",
       "2    2  1.138597e+20      Joe Nicolas 1990-12-31     5.0   \n",
       "3    3  1.004403e+20  Chef Marsha Kiv 1990-12-31     3.0   \n",
       "4    4  1.178880e+20      Melody Tsai 1990-12-31     5.0   \n",
       "..  ..           ...              ...        ...     ...   \n",
       "95  95  1.183500e+20            Dan F 2005-08-31     5.0   \n",
       "96  96  1.183500e+20            Dan F 2005-08-31     4.0   \n",
       "97  97  1.051016e+20      Mac Frazier 2005-10-22     2.0   \n",
       "98  98  1.051016e+20      Mac Frazier 2005-10-22     2.0   \n",
       "99  99  1.051016e+20      Mac Frazier 2005-10-22     2.0   \n",
       "\n",
       "                                                 text  resp  \\\n",
       "0   Flatbreads are delicious for appetizers to sha...  None   \n",
       "1   well-run and clearly a popular \"happening\" spo...  None   \n",
       "2                                                None  None   \n",
       "3   I have been to many of Chef Garces' restaurant...  None   \n",
       "4                                         Great Food!  None   \n",
       "..                                                ...   ...   \n",
       "95  this could be the best byo in the burbs.  ever...  None   \n",
       "96  this neighborhood tap room really cooks.  ever...  None   \n",
       "97  great traditional german food! the setting is ...  None   \n",
       "98  cute, themed diner, with good shakes and burge...  None   \n",
       "99                                               None  None   \n",
       "\n",
       "                                  gmap_id                business_name  \\\n",
       "0   0x89c6944bbcf4f9fb:0x77c6109d1ce368f4                   Seasons 52   \n",
       "1   0x89c6c630798d07a5:0x7da1292822f531db                 Alma de Cuba   \n",
       "2   0x89c6c625b14dea8b:0xb31072102487e2fe                      VALANNI   \n",
       "3   0x89c6c6f86d1010ad:0x2fb936cf6717b44d                     Distrito   \n",
       "4   0x89c6c60e85b145bf:0xb189cdb4c35a41f3  South Philadelphia Tap Room   \n",
       "..                                    ...                          ...   \n",
       "95  0x89c6c07607056697:0x2b8e2876e3a9517e                         Sola   \n",
       "96  0x89c6c898b3eb1341:0x12cfe87713184d11                New Wave Cafe   \n",
       "97  0x89c6afbf8417a279:0x3dd203c5ec7db1e3              Otto's Brauhaus   \n",
       "98  0x89c6c2f455344797:0x12987ea5eabacd5a                Nifty Fifty's   \n",
       "99  0x89c6b0ea14e77aeb:0xb00d8934ef9a7781                   La Pergola   \n",
       "\n",
       "                                              address  \\\n",
       "0   Seasons 52, 160 N Gulph Rd Suite 101, King of ...   \n",
       "1   Alma de Cuba, 1623 Walnut St, Philadelphia, PA...   \n",
       "2   VALANNI, 1229 Spruce St, Philadelphia, PA 1910...   \n",
       "3   Distrito, 3945 Chestnut St, Philadelphia, PA 1...   \n",
       "4   South Philadelphia Tap Room, 1509 Mifflin St, ...   \n",
       "..                                                ...   \n",
       "95       Sola, 614 Lancaster Ave, Bryn Mawr, PA 19010   \n",
       "96  New Wave Cafe, 784 S 3rd St, Philadelphia, PA ...   \n",
       "97  Otto's Brauhaus, 233 Easton Rd, Horsham, PA 19044   \n",
       "98  Nifty Fifty's, 1900 MacDade Boulevard, Folsom,...   \n",
       "99     La Pergola, 726 West Ave, Jenkintown, PA 19046   \n",
       "\n",
       "                                          description   latitude  longitude  \\\n",
       "0   Rotating menu of seasonal American dishes alon...  40.085768 -75.394432   \n",
       "1   Fusion fare with Cuban influences; happy hour ...  39.950078 -75.168517   \n",
       "2   Distinctive Mediterranean-Latin dishes served ...  39.946850 -75.162217   \n",
       "3   Mexican bites & potent margaritas flavor this ...  39.955999 -75.202017   \n",
       "4   American beer bar featuring a lineup of drafts...  39.927216 -75.171477   \n",
       "..                                                ...        ...        ...   \n",
       "95  New American seasonal cuisine served in a cozy...  40.018088 -75.312039   \n",
       "96  Locals fill this casual sports bar to chat wit...  39.938080 -75.148527   \n",
       "97  Prime rib, steaks, seafood & German specialtie...  40.175800 -75.128520   \n",
       "98  Nostalgic, '50s-style American diner with burg...  39.895706 -75.314895   \n",
       "99  Hummus & Middle Eastern fare shares menu space...  40.095844 -75.126244   \n",
       "\n",
       "    avg_rating  num_of_reviews price state  \\\n",
       "0          4.4            1618    $$    PA   \n",
       "1          4.4             998   $$$    PA   \n",
       "2          4.3             448    $$    PA   \n",
       "3          4.0             838    $$    PA   \n",
       "4          4.6             746    $$    PA   \n",
       "..         ...             ...   ...   ...   \n",
       "95         4.3              28   $$$    PA   \n",
       "96         4.4             435     $    PA   \n",
       "97         4.0             678    $$    PA   \n",
       "98         4.4            3156     $    PA   \n",
       "99         4.3              58    $$    PA   \n",
       "\n",
       "                                                  url  \n",
       "0   https://www.google.com/maps/place//data=!4m2!3...  \n",
       "1   https://www.google.com/maps/place//data=!4m2!3...  \n",
       "2   https://www.google.com/maps/place//data=!4m2!3...  \n",
       "3   https://www.google.com/maps/place//data=!4m2!3...  \n",
       "4   https://www.google.com/maps/place//data=!4m2!3...  \n",
       "..                                                ...  \n",
       "95  https://www.google.com/maps/place//data=!4m2!3...  \n",
       "96  https://www.google.com/maps/place//data=!4m2!3...  \n",
       "97  https://www.google.com/maps/place//data=!4m2!3...  \n",
       "98  https://www.google.com/maps/place//data=!4m2!3...  \n",
       "99  https://www.google.com/maps/place//data=!4m2!3...  \n",
       "\n",
       "[100 rows x 18 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new.head(100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new.head().to_csv('./final_mergxzced_pa.csv',index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully dumped to table 'main' in PostgreSQL!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "# Database connection parameters\n",
    "DB_HOST = \"localhost\"  # e.g., \"localhost\"\n",
    "DB_PORT = \"5432\"  # Default PostgreSQL port\n",
    "DB_NAME = \"Capstone\"\n",
    "DB_USER = \"postgres\"\n",
    "DB_PASSWORD = \"Google#13\"\n",
    "TABLE_NAME = \"backup\"\n",
    "CHUNK_SIZE = 4000  # Adjust as needed\n",
    "\n",
    "# Create a SQLAlchemy engine\n",
    "engine = create_engine(f\"postgresql+psycopg2://{DB_USER}:{DB_PASSWORD}@{DB_HOST}:{DB_PORT}/{DB_NAME}\")\n",
    "\n",
    "\n",
    "\n",
    "def insert_chunk(chunk, engine, table_name):\n",
    "    \"\"\"\n",
    "    Inserts a chunk of pandas DataFrame rows into a table in the given database engine.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Write to SQL in 'append' mode\n",
    "        chunk.to_sql(table_name, engine, if_exists=\"append\", index=False)\n",
    "    except Exception as e:\n",
    "        print(f\"Error inserting chunk: {e}\")\n",
    "\n",
    "\n",
    "# Perform sequential chunk-wise insertion\n",
    "try:\n",
    "    total_rows = len(df_new)\n",
    "    for start in range(0, total_rows, CHUNK_SIZE):\n",
    "        # Slicing the DataFrame chunk\n",
    "        chunk = df_new.iloc[start: start + CHUNK_SIZE]\n",
    "        insert_chunk(chunk, engine, TABLE_NAME)\n",
    "    print(f\"Data successfully dumped to table '{TABLE_NAME}' in PostgreSQL!\")\n",
    "except Exception as e:\n",
    "    print(\"Error:\", e)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 20\u001b[0m\n\u001b[0;32m     17\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSELECT user_id, text FROM main WHERE text != \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNone\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m;\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Read into DataFrame\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_sql\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Display DataFrame\u001b[39;00m\n\u001b[0;32m     23\u001b[0m df\u001b[38;5;241m.\u001b[39mhead()\n",
      "File \u001b[1;32mc:\\Users\\rushi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\sql.py:734\u001b[0m, in \u001b[0;36mread_sql\u001b[1;34m(sql, con, index_col, coerce_float, params, parse_dates, columns, chunksize, dtype_backend, dtype)\u001b[0m\n\u001b[0;32m    724\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pandas_sql\u001b[38;5;241m.\u001b[39mread_table(\n\u001b[0;32m    725\u001b[0m         sql,\n\u001b[0;32m    726\u001b[0m         index_col\u001b[38;5;241m=\u001b[39mindex_col,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    731\u001b[0m         dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m    732\u001b[0m     )\n\u001b[0;32m    733\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpandas_sql\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_query\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    735\u001b[0m \u001b[43m        \u001b[49m\u001b[43msql\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    736\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_col\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    737\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    738\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcoerce_float\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcoerce_float\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    739\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparse_dates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparse_dates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    740\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    741\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype_backend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    742\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    743\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\rushi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\sql.py:1836\u001b[0m, in \u001b[0;36mSQLDatabase.read_query\u001b[1;34m(self, sql, index_col, coerce_float, parse_dates, params, chunksize, dtype, dtype_backend)\u001b[0m\n\u001b[0;32m   1779\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mread_query\u001b[39m(\n\u001b[0;32m   1780\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1781\u001b[0m     sql: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1788\u001b[0m     dtype_backend: DtypeBackend \u001b[38;5;241m|\u001b[39m Literal[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1789\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Iterator[DataFrame]:\n\u001b[0;32m   1790\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1791\u001b[0m \u001b[38;5;124;03m    Read SQL query into a DataFrame.\u001b[39;00m\n\u001b[0;32m   1792\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1834\u001b[0m \n\u001b[0;32m   1835\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1836\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43msql\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1837\u001b[0m     columns \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39mkeys()\n\u001b[0;32m   1839\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\rushi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\sql.py:1659\u001b[0m, in \u001b[0;36mSQLDatabase.execute\u001b[1;34m(self, sql, params)\u001b[0m\n\u001b[0;32m   1657\u001b[0m args \u001b[38;5;241m=\u001b[39m [] \u001b[38;5;28;01mif\u001b[39;00m params \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m [params]\n\u001b[0;32m   1658\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(sql, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m-> 1659\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcon\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexec_driver_sql\u001b[49m\u001b[43m(\u001b[49m\u001b[43msql\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1660\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcon\u001b[38;5;241m.\u001b[39mexecute(sql, \u001b[38;5;241m*\u001b[39margs)\n",
      "File \u001b[1;32mc:\\Users\\rushi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sqlalchemy\\engine\\base.py:1776\u001b[0m, in \u001b[0;36mConnection.exec_driver_sql\u001b[1;34m(self, statement, parameters, execution_options)\u001b[0m\n\u001b[0;32m   1771\u001b[0m execution_options \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_execution_options\u001b[38;5;241m.\u001b[39mmerge_with(\n\u001b[0;32m   1772\u001b[0m     execution_options\n\u001b[0;32m   1773\u001b[0m )\n\u001b[0;32m   1775\u001b[0m dialect \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdialect\n\u001b[1;32m-> 1776\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_context\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1777\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdialect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1778\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdialect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecution_ctx_cls\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_init_statement\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1779\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1780\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1781\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexecution_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1782\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1783\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdistilled_parameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1784\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1786\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ret\n",
      "File \u001b[1;32mc:\\Users\\rushi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sqlalchemy\\engine\\base.py:1843\u001b[0m, in \u001b[0;36mConnection._execute_context\u001b[1;34m(self, dialect, constructor, statement, parameters, execution_options, *args, **kw)\u001b[0m\n\u001b[0;32m   1841\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exec_insertmany_context(dialect, context)\n\u001b[0;32m   1842\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1843\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_exec_single_context\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1844\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdialect\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\n\u001b[0;32m   1845\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\rushi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sqlalchemy\\engine\\base.py:1983\u001b[0m, in \u001b[0;36mConnection._exec_single_context\u001b[1;34m(self, dialect, context, statement, parameters)\u001b[0m\n\u001b[0;32m   1980\u001b[0m     result \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39m_setup_result_proxy()\n\u001b[0;32m   1982\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m-> 1983\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle_dbapi_exception\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1984\u001b[0m \u001b[43m        \u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstr_statement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meffective_parameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcursor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\n\u001b[0;32m   1985\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1987\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\rushi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sqlalchemy\\engine\\base.py:2355\u001b[0m, in \u001b[0;36mConnection._handle_dbapi_exception\u001b[1;34m(self, e, statement, parameters, cursor, context, is_sub_exec)\u001b[0m\n\u001b[0;32m   2353\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2354\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m exc_info[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 2355\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m exc_info[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mwith_traceback(exc_info[\u001b[38;5;241m2\u001b[39m])\n\u001b[0;32m   2356\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m   2357\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reentrant_error\n",
      "File \u001b[1;32mc:\\Users\\rushi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sqlalchemy\\engine\\base.py:1964\u001b[0m, in \u001b[0;36mConnection._exec_single_context\u001b[1;34m(self, dialect, context, statement, parameters)\u001b[0m\n\u001b[0;32m   1962\u001b[0m                 \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m   1963\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m evt_handled:\n\u001b[1;32m-> 1964\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdialect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_execute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1965\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcursor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstr_statement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meffective_parameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\n\u001b[0;32m   1966\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1968\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_events \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine\u001b[38;5;241m.\u001b[39m_has_events:\n\u001b[0;32m   1969\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch\u001b[38;5;241m.\u001b[39mafter_cursor_execute(\n\u001b[0;32m   1970\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1971\u001b[0m         cursor,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1975\u001b[0m         context\u001b[38;5;241m.\u001b[39mexecutemany,\n\u001b[0;32m   1976\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\rushi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sqlalchemy\\engine\\default.py:942\u001b[0m, in \u001b[0;36mDefaultDialect.do_execute\u001b[1;34m(self, cursor, statement, parameters, context)\u001b[0m\n\u001b[0;32m    941\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdo_execute\u001b[39m(\u001b[38;5;28mself\u001b[39m, cursor, statement, parameters, context\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m--> 942\u001b[0m     \u001b[43mcursor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\rushi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\encodings\\utf_8.py:15\u001b[0m, in \u001b[0;36mdecode\u001b[1;34m(input, errors)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m### Codec APIs\u001b[39;00m\n\u001b[0;32m     13\u001b[0m encode \u001b[38;5;241m=\u001b[39m codecs\u001b[38;5;241m.\u001b[39mutf_8_encode\n\u001b[1;32m---> 15\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28minput\u001b[39m, errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m codecs\u001b[38;5;241m.\u001b[39mutf_8_decode(\u001b[38;5;28minput\u001b[39m, errors, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mIncrementalEncoder\u001b[39;00m(codecs\u001b[38;5;241m.\u001b[39mIncrementalEncoder):\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Example connection string (modify based on your database)\n",
    "DB_HOST = \"rgx.ddns.net\"  # e.g., \"localhost\"\n",
    "DB_PORT = \"5432\"  # Default PostgreSQL port\n",
    "DB_NAME = \"Capstone\"\n",
    "DB_USER = \"postgres\"\n",
    "DB_PASSWORD = \"Google#13\"\n",
    "TABLE_NAME = \"main\"\n",
    "CHUNK_SIZE = 600  # Adjust as needed\n",
    "\n",
    "# Create a SQLAlchemy engine\n",
    "engine = create_engine(f\"postgresql+psycopg2://{DB_USER}:{DB_PASSWORD}@{DB_HOST}:{DB_PORT}/{DB_NAME}\")\n",
    "\n",
    "# SQL query to fetch user_id and text\n",
    "query = \"SELECT user_id, text FROM main WHERE text != 'None';\"\n",
    "\n",
    "# Read into DataFrame\n",
    "df = pd.read_sql(query, engine)\n",
    "\n",
    "# Display DataFrame\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mdf\u001b[49m\u001b[38;5;241m.\u001b[39mhead()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello', ',', 'this', 'is', 'a', 'test', '.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "text = \"Hello, this is a test.\"\n",
    "print(word_tokenize(text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, text\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from multiprocessing import Pool, cpu_count\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    \n",
    "    # Tokenize text\n",
    "    tokens = word_tokenize(text)\n",
    "\n",
    "    # Remove stopwords\n",
    "    tokens = [word for word in tokens if word.lower() not in set(stopwords.words('english'))]\n",
    "\n",
    "    return ' '.join(tokens)\n",
    "Session = sessionmaker(bind=engine)\n",
    "\n",
    "# Function to update a batch of rows\n",
    "def update_batch(batch):\n",
    "    session = Session()\n",
    "    try:\n",
    "        query = text(f\"\"\"\n",
    "            UPDATE {TABLE_NAME}\n",
    "            SET clean_text = :clean_text\n",
    "            WHERE user_id = :user_id\n",
    "        \"\"\")\n",
    "        session.execute(query, batch)\n",
    "        session.commit()\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        session.rollback()\n",
    "    finally:\n",
    "        session.close()\n",
    "\n",
    "# Clean text in parallel\n",
    "with Pool(cpu_count()) as pool:\n",
    "    df['clean_text'] = pool.map(clean_text, df['text'])\n",
    "\n",
    "# Convert DataFrame to list of dictionaries for batch update\n",
    "data = df[['user_id', 'clean_text']].to_dict(orient='records')\n",
    "\n",
    "# Process updates in parallel\n",
    "num_workers = cpu_count()\n",
    "batch_size = len(data) // num_workers\n",
    "\n",
    "with Pool(num_workers) as pool:\n",
    "    pool.map(update_batch, [data[i:i + batch_size] for i in range(0, len(data), batch_size)])\n",
    "\n",
    "print(\"Update completed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting text cleaning and sentiment analysis with VADER...\n",
      "Number of records in DataFrame: (12032232, 2)\n",
      "Detected 32 CPU cores.\n",
      "Created 240645 batch(es) with batch_size=50.\n",
      "Initializing multiprocessing Pool...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches:   0%|          | 0/240645 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# SQLAlchemy imports\n",
    "from sqlalchemy import create_engine, text\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "\n",
    "# NLTK imports\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "# Multiprocessing\n",
    "from multiprocessing import Pool, cpu_count\n",
    "\n",
    "# For progress bar\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ------------------------------------------------------------------------\n",
    "# 1. SETUP: Create your engine, session, and define your table name\n",
    "# ------------------------------------------------------------------------\n",
    "# Example (uncomment or replace with actual):\n",
    "# engine = create_engine(\"postgresql://user:pass@host:port/dbname\")\n",
    "Session = sessionmaker(bind=engine)\n",
    "TABLE_NAME = \"main\"\n",
    "\n",
    "# Initialize VADER sentiment analyzer (do this once, outside the worker function)\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "\n",
    "# ------------------------------------------------------------------------\n",
    "# 2. Define your text-cleaning function\n",
    "# ------------------------------------------------------------------------\n",
    "def clear_text(text):\n",
    "    \"\"\"\n",
    "    Cleans the text by removing extra whitespace, tokenizing,\n",
    "    and removing stopwords.\n",
    "    \"\"\"\n",
    "    # Basic whitespace cleanup\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "    # Tokenize\n",
    "    tokens = word_tokenize(text)\n",
    "\n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [word for word in tokens if word.lower() not in stop_words]\n",
    "\n",
    "    # Rejoin cleaned tokens\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "# ------------------------------------------------------------------------\n",
    "# 3. Define sentiment computation function\n",
    "# ------------------------------------------------------------------------\n",
    "def compute_sentiment(cleaned_text):\n",
    "    \"\"\"\n",
    "    Computes the sentiment score using VADER.\n",
    "    Returns the 'compound' score as a simple representative metric.\n",
    "    \"\"\"\n",
    "    scores = sid.polarity_scores(cleaned_text)\n",
    "    return scores['compound']\n",
    "\n",
    "# ------------------------------------------------------------------------\n",
    "# 4. Define function to process and update a *batch* of rows\n",
    "# ------------------------------------------------------------------------\n",
    "def process_and_update_batch(batch):\n",
    "    \"\"\"\n",
    "    Cleans text and computes sentiment for each row in the batch,\n",
    "    then updates the database in a single transaction.\n",
    "    Returns True if successful (for tqdm progress).\n",
    "    \"\"\"\n",
    "    session = Session()\n",
    "    try:\n",
    "        # Optional: Use tqdm.write to keep the progress bar intact\n",
    "        # (If you want to see which batch is being processed)\n",
    "        tqdm.write(f\"Processing a batch of size {len(batch)}...\")\n",
    "\n",
    "        for row in batch:\n",
    "            user_id = row['user_id']\n",
    "            raw_text = row['text']\n",
    "\n",
    "            # Clean the text\n",
    "            cleaned_text = clear_text(raw_text)\n",
    "\n",
    "            # Compute sentiment\n",
    "            text_sentiment = compute_sentiment(cleaned_text)\n",
    "\n",
    "            # Execute the update\n",
    "            update_query = text(f\"\"\"\n",
    "                UPDATE {TABLE_NAME}\n",
    "                SET clear_text = :clean_text,\n",
    "                    text_sentiment = :text_sentiment\n",
    "                WHERE user_id = :user_id\n",
    "            \"\"\")\n",
    "            session.execute(\n",
    "                update_query,\n",
    "                {\n",
    "                    \"clean_text\": cleaned_text,\n",
    "                    \"text_sentiment\": text_sentiment,\n",
    "                    \"user_id\": user_id\n",
    "                }\n",
    "            )\n",
    "\n",
    "        # Commit once per batch\n",
    "        session.commit()\n",
    "\n",
    "        # Optional success message\n",
    "        tqdm.write(\"Batch successfully committed!\")\n",
    "\n",
    "    except Exception as e:\n",
    "        # Print the error using tqdm.write (to avoid breaking progress bar)\n",
    "        tqdm.write(f\"Error processing batch: {e}\")\n",
    "        session.rollback()\n",
    "        return False\n",
    "\n",
    "    finally:\n",
    "        session.close()\n",
    "\n",
    "    return True\n",
    "\n",
    "# ------------------------------------------------------------------------\n",
    "# 5. Main logic with a DataFrame and parallel batching\n",
    "# ------------------------------------------------------------------------\n",
    "if __name__ == '__main__':\n",
    "    # Example DataFrame with columns 'user_id' and 'text'\n",
    "    # In practice, you might read from your DB:\n",
    "    # df = pd.read_sql(\"SELECT user_id, text FROM main\", engine)\n",
    "\n",
    "    # df = pd.DataFrame([\n",
    "    #     {'user_id': 1, 'text': \"This is an example!\"},\n",
    "    #     {'user_id': 2, 'text': \"Another example text, with some negativity...\"},\n",
    "    #     {'user_id': 3, 'text': \"I love using Python for data analysis!\"},\n",
    "    #     # ... many more rows ...\n",
    "    # ])\n",
    "\n",
    "    # Print some details\n",
    "    print(\"Starting text cleaning and sentiment analysis with VADER...\")\n",
    "    print(f\"Number of records in DataFrame: {df.shape}\")\n",
    "\n",
    "    # Create the data as list of dicts (if not already)\n",
    "    # data = df.to_dict(orient='records')\n",
    "\n",
    "    # Number of CPU cores\n",
    "    num_workers = cpu_count()\n",
    "    print(f\"Detected {num_workers} CPU cores.\")\n",
    "\n",
    "    # --------------------------------------------------------------------\n",
    "    # 6. Create chunks (batches) of size 50\n",
    "    # --------------------------------------------------------------------\n",
    "    batch_size = 50\n",
    "    batches = [df[i : i + batch_size] for i in range(0, len(df), batch_size)]\n",
    "    print(f\"Created {len(batches)} batch(es) with batch_size={batch_size}.\")\n",
    "\n",
    "    # --------------------------------------------------------------------\n",
    "    # 7. Distribute these batches across CPU cores in parallel,\n",
    "    #    with a TQDM progress bar\n",
    "    # --------------------------------------------------------------------\n",
    "    print(\"Initializing multiprocessing Pool...\")\n",
    "    with Pool(num_workers) as pool:\n",
    "        # imap yields results one by one, so we can increment tqdm for each batch\n",
    "        for _ in tqdm(pool.imap(process_and_update_batch, batches),\n",
    "                      total=len(batches),\n",
    "                      desc=\"Processing Batches\"):\n",
    "            pass\n",
    "\n",
    "    print(\"All batches processed, sentiment scored, and updates committed successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# SQLAlchemy imports\n",
    "from sqlalchemy import create_engine, text\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "\n",
    "# Hugging Face Transformers for GPU-based sentiment\n",
    "import torch\n",
    "from transformers import pipeline\n",
    "\n",
    "# Multiprocessing\n",
    "from multiprocessing import Pool, cpu_count\n",
    "\n",
    "# TQDM progress bar (optional)\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ------------------------------------------------------------------------\n",
    "# 1. SETUP: Create your engine, session, and define your table name\n",
    "# ------------------------------------------------------------------------\n",
    "# engine = create_engine(\"postgresql://user:pass@host:port/dbname\")  # Example\n",
    "Session = sessionmaker(bind=engine)\n",
    "TABLE_NAME = \"main\"\n",
    "\n",
    "# ------------------------------------------------------------------------\n",
    "# 2. GPU-Accelerated Sentiment Analysis Pipeline\n",
    "# ------------------------------------------------------------------------\n",
    "#   device=0 uses the first GPU (if torch.cuda.is_available() is True),\n",
    "#   otherwise it falls back to CPU with device=-1.\n",
    "device = 0 if torch.cuda.is_available() else -1\n",
    "\n",
    "# Load a pre-trained sentiment model.\n",
    "# You can pick any model from https://huggingface.co/models?pipeline_tag=sentiment-analysis\n",
    "sentiment_pipeline = pipeline(\n",
    "    \"sentiment-analysis\",\n",
    "    model=\"nlptown/bert-base-multilingual-uncased-sentiment\",\n",
    "    device=device\n",
    ")\n",
    "\n",
    "# ------------------------------------------------------------------------\n",
    "# 3. Text-cleaning function (CPU-based)\n",
    "# ------------------------------------------------------------------------\n",
    "def clear_text(text):\n",
    "    \"\"\"\n",
    "    Basic cleanup via regex, tokenization, and optional removal of stopwords.\n",
    "    \"\"\"\n",
    "    # Basic whitespace cleanup\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "# ------------------------------------------------------------------------\n",
    "# 4. GPU-based sentiment function\n",
    "# ------------------------------------------------------------------------\n",
    "def compute_sentiment_gpu(cleaned_text):\n",
    "    \"\"\"\n",
    "    Runs the text through a Hugging Face Transformers sentiment pipeline.\n",
    "    Returns label (e.g., \"1 star\", \"5 stars\", \"POSITIVE\"/\"NEGATIVE\", etc.)\n",
    "    and a confidence score.\n",
    "    \"\"\"\n",
    "    # The pipeline returns a list of results, e.g. [{'label': 'POSITIVE', 'score': 0.99}]\n",
    "    results = sentiment_pipeline(cleaned_text)\n",
    "    result = results[0]  # first (and only) item\n",
    "    label = result[\"label\"]\n",
    "    score = result[\"score\"]\n",
    "    return label, score\n",
    "\n",
    "# ------------------------------------------------------------------------\n",
    "# 5. Function to process and update a *batch* of rows\n",
    "# ------------------------------------------------------------------------\n",
    "def process_and_update_batch(batch):\n",
    "    \"\"\"\n",
    "    Cleans text and computes sentiment for each row in the batch (GPU-based),\n",
    "    then updates the database in a single transaction.\n",
    "    \"\"\"\n",
    "    session = Session()\n",
    "    try:\n",
    "        for row in batch:\n",
    "            user_id = row[\"user_id\"]\n",
    "            raw_text = row[\"text\"]\n",
    "\n",
    "            # 1) Clean text (CPU-based minimal cleaning)\n",
    "            cleaned_text = clear_text(raw_text)\n",
    "\n",
    "            # 2) Compute sentiment with GPU\n",
    "            label, score = compute_sentiment_gpu(cleaned_text)\n",
    "\n",
    "            # 3) Update the database\n",
    "            update_query = text(f\"\"\"\n",
    "                UPDATE {TABLE_NAME}\n",
    "                SET clean_text = :clean_text,\n",
    "                    text_sentiment = :text_sentiment,\n",
    "                    text_sentiment_score = :text_score\n",
    "                WHERE user_id = :user_id\n",
    "            \"\"\")\n",
    "\n",
    "            session.execute(\n",
    "                update_query,\n",
    "                {\n",
    "                    \"clean_text\": cleaned_text,\n",
    "                    \"text_sentiment\": label,\n",
    "                    \"text_score\": score,\n",
    "                    \"user_id\": user_id,\n",
    "                }\n",
    "            )\n",
    "\n",
    "        # Commit once for the entire batch\n",
    "        session.commit()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing batch: {e}\")\n",
    "        session.rollback()\n",
    "    finally:\n",
    "        session.close()\n",
    "\n",
    "    return True\n",
    "\n",
    "# ------------------------------------------------------------------------\n",
    "# 6. Main logic with parallel batch processing\n",
    "# ------------------------------------------------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    # For demonstration, create an example DataFrame with columns 'user_id' and 'text'\n",
    "    # In practice, you'd read from your DB, e.g.:\n",
    "    # df = pd.read_sql(\"SELECT user_id, text FROM main\", engine)\n",
    "\n",
    "\n",
    "\n",
    "    # Number of CPU cores\n",
    "    num_workers = cpu_count()\n",
    "    print(f\"Detected {num_workers} CPU cores (processes).\")\n",
    "\n",
    "    # Batch size\n",
    "    batch_size = 5\n",
    "    batches = [df[i : i + batch_size] for i in range(0, len(df), batch_size)]\n",
    "    print(f\"Created {len(batches)} batch(es) with batch_size={batch_size}.\")\n",
    "\n",
    "    # Use multiprocessing pool\n",
    "    with Pool(num_workers) as pool:\n",
    "        # tqdm for a progress bar if desired\n",
    "        for _ in tqdm(pool.imap(process_and_update_batch, batches),\n",
    "                      total=len(batches),\n",
    "                      desc=\"Processing Batches\"):\n",
    "            pass\n",
    "\n",
    "    print(\"All batches processed with GPU-based sentiment and updates committed successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment(text):\n",
    "    sentiment_score = sia.polarity_scores(text)['compound']\n",
    "    \n",
    "    # Classify sentiment\n",
    "    if sentiment_score >= 0.05:\n",
    "        sentiment = \"Positive\"\n",
    "    elif sentiment_score <= -0.05:\n",
    "        sentiment = \"Negative\"\n",
    "    else:\n",
    "        sentiment = \"Neutral\"\n",
    "    \n",
    "    return sentiment_score, sentiment\n",
    "\n",
    "# Apply sentiment analysis\n",
    "df[['sentiment_score', 'sentiment_category']] = df['clean_text'].apply(lambda x: pd.Series(get_sentiment(x)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install ace_tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display DataFrame\n",
    "import ace_tools as tools\n",
    "tools.display_dataframe_to_user(name=\"Sentiment Analysis Data\", dataframe=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Example connection string (modify based on your database)\n",
    "DB_HOST = \"localhost\"  # e.g., \"localhost\"\n",
    "DB_PORT = \"5432\"  # Default PostgreSQL port\n",
    "DB_NAME = \"Capstone\"\n",
    "DB_USER = \"postgres\"\n",
    "DB_PASSWORD = \"Google#13\"\n",
    "TABLE_NAME = \"main\"\n",
    "CHUNK_SIZE = 600  # Adjust as needed\n",
    "\n",
    "# Create a SQLAlchemy engine\n",
    "engine = create_engine(f\"postgresql+psycopg2://{DB_USER}:{DB_PASSWORD}@{DB_HOST}:{DB_PORT}/{DB_NAME}\")\n",
    "\n",
    "# SQL query to fetch user_id and text\n",
    "query = \"SELECT gmap_id, latitude, longitude FROM main\"\n",
    "\n",
    "# Read into DataFrame\n",
    "df_loc = pd.read_sql(query, engine)\n",
    "\n",
    "# Display DataFrame\n",
    "df_loc.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install geopy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from geopy.geocoders import Nominatim\n",
    "from geopy.exc import GeocoderTimedOut\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize geocoder\n",
    "geolocator = Nominatim(user_agent=\"geoapiExercises\")\n",
    "\n",
    "def get_zipcode(lat, lon):\n",
    "    \"\"\"\n",
    "    Fetches ZIP code from latitude and longitude using Nominatim.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        location = geolocator.reverse((lat, lon), exactly_one=True)\n",
    "        if location and 'postcode' in location.raw['address']:\n",
    "            return location.raw['address']['postcode']\n",
    "        else:\n",
    "            return None  # No ZIP code found\n",
    "    except GeocoderTimedOut:\n",
    "        return \"Timeout\"\n",
    "\n",
    "# Example latitude and longitude values\n",
    "\n",
    "\n",
    "# Apply function to get ZIP codes\n",
    "df_loc['zip_code'] = df_loc.apply(lambda row: get_zipcode(row['latitude'], row['longitude']), axis=1)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
